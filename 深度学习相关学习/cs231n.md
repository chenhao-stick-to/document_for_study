# 1.CNN

全连接层产生大量训练参数

# 2.RNN

通过当前的输入数据以及上一个隐藏层数据，再通过共享的权重矩阵来计算下一隐藏层数据，并且计算出对应的输出，在计算单个loss，总loss等于所有单个loss之和。反向传播更新梯度的时候，我们分别计算每个时间步的局部梯度，则最后我们的最终梯度为所局部梯度之和。  



![image-20230403134948700](../../../../AppData/Roaming/Typora/typora-user-images/image-20230403134948700.png)



**计算loss是时一般我们会局部的计算序列损失，然后更新，因为序列很大的话且我们不做切分，那么就会消耗很大的内存，这是方法不可行的。局部窗口计算损失。**

![image-20230403142352861](../../../../AppData/Roaming/Typora/typora-user-images/image-20230403142352861.png)





LSTM增加遗忘门，为了避免序列层数过多导致的梯度消失现象，初始化为1的随机分布，训练过程中进行更新。

# 3.语义分割以及目标识别

1.语义分割，典型的u-net网络，先下采样再上采样，最后进行sofmax交叉熵计算损失。

对每个像素点进行分类，计算比较复杂。

2.rnn网络，先进行区域性的感兴趣区域的选取，然后对每个感兴趣区域进行相应的边界框回归以及分类计算。

faster-rcnn,先cnn提取特征图，再选择感兴趣的区域，分别计算边界框的类别分类（是否为背景），进行一定的修正，然后再在特征图上进行边界框的回归计算以及框中内容的分类计算。

![image-20230403165249223](../../../../AppData/Roaming/Typora/typora-user-images/image-20230403165249223.png)

3.yolo则是将图像分为很多的方格，每个方格对应n个边界框，针对每个边界框我们有五个参数（x,y,w,h,置信度）,对每个方格我们有自己分类.

![image-20230403165224494](../../../../AppData/Roaming/Typora/typora-user-images/image-20230403165224494.png)

针对master r-cnn：既有faster r-cnn的思想，也有在局部感兴趣区域进行语义分割。

![image-20230403165408553](../../../../AppData/Roaming/Typora/typora-user-images/image-20230403165408553.png)

![image-20230403165606362](../../../../AppData/Roaming/Typora/typora-user-images/image-20230403165606362.png)





