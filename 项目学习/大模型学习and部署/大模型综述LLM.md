# 引言
语言建模（LM）是提高机器语言智能的主要方法之一。一般来说，LM 旨在对词序列的生成概率进行建模，以预测未来（或缺失）tokens的概率。主要四个阶段：
- 统计语言模型SLM，兴起于20世纪90年代，基于马尔可夫等传统机器学习来预测模型。（信息检索IR，NLP领域）。维数灾难问题。
- 神经语言模型NLM，循环神经网络RNN等。各种上下文特征的表示方法，分布式词向量，word2vec等。
- 预训练语言模型PLM，预训练一个双向LSTM来捕捉语言上下文的此表示，下游再微调一个网络；再到并行化的transformer，BERT。预训练的上下文感知此作为通用语义非常有效。基本确定了"预训练加微调"学习范式，通过统一的上下文表达加上微调，来适配不同的下游任务。
- **大语言模型LLM**，研究发现扩大上游的PLM以及数据的大小，可以提升下游的模型性能（即上游的上下文特征表示更加准确）；且当模型大小的很大时，在解决复杂任务上展示了惊人能力（涌现能力）。和PLM区别有三点：一是LLM大模型带来的涌现能力，二是LLM改变人类开发和使用人工智能算法方式，gpt系列依靠提示接口，三是LLM的发展不区分研究和工程，不管训练还是部署，都需要如大规模数据处理，分布式并行训练等工程上的复杂问题。
LLM的出现看到了通往AGI的大门。chatgpt（聊天机器人），gpt-4整合视觉支持多模态输入。Copilot自动化办公工作等。
**问题**？
LLM尽管有很多应用，但是其基本原理尚未充分了解。
研究界训练出有能力的LLM很难，主要工业界。
LLM与人类价值观或偏好保持一致有挑战性。
本文主要四方面研究LLM。
一是预训练，二是适配微调（有效，安全，针对性的微调），三是使用（解决下游任务），四是能力评估（评估LLM能力和现有的经验性发现）
# 概述
LLM背景以及GPT系列模型计数演变
## 大语言模型背景
### LLM的扩展法则
扩展可以大幅度提高LLM的模型能力
- KM扩展法则：
描述神经网络语言模型性能和模型规模（N），数据集规模（D），训练计算量（C）的幂律关系。